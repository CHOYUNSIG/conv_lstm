{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch torchvision\n",
    "%pip install numpy\n",
    "%pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "def get_mhi(prev_img, next_img):\n",
    "    \"\"\"\n",
    "    두 이미지로부터 모션 히스토리 이미지를 계산해 반환하는 함수\n",
    "    :param prev_img: 이전 이미지\n",
    "    :param next_img: 이후 이미지\n",
    "    :return: 모션 히스토리 이미지\n",
    "    \"\"\"\n",
    "    diff = cv2.absdiff(prev_img, next_img)\n",
    "    gray_diff = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "    return gray_diff\n",
    "\n",
    "\n",
    "def get_mhis(video):\n",
    "    \"\"\"\n",
    "    비디오 데이터를 모션 히스토리 이미지의 리스트로 반환하는 함수\n",
    "    :param video: cv2 비디오\n",
    "    :return: 모션 히스토리 이미지 리스트\n",
    "    \"\"\"\n",
    "    result = []\n",
    "\n",
    "    prev_img = None\n",
    "    while True:\n",
    "        ret, curr_img = video.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # 모션 히스토리 이미지 생성\n",
    "        if prev_img is not None:\n",
    "            mhi = get_mhi(prev_img, curr_img)\n",
    "            result.append(mhi)\n",
    "\n",
    "        prev_img = curr_img\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class ActionDataset(Dataset):\n",
    "    def __init__(self, root_dir, frame_count=30):\n",
    "        self.root_dir = root_dir\n",
    "        self.samples = []\n",
    "        self.label_map = {}\n",
    "        self.frame_count = frame_count\n",
    "        \n",
    "        # 라벨 매핑 생성\n",
    "        for idx, label in enumerate(os.listdir(root_dir)):\n",
    "            self.label_map[label] = idx\n",
    "            \n",
    "        # 데이터 경로와 라벨 수집\n",
    "        for label in os.listdir(root_dir):\n",
    "            label_dir = os.path.join(root_dir, label)\n",
    "            n = 0\n",
    "            for video_file in os.listdir(label_dir):\n",
    "                if video_file.endswith('.avi'):\n",
    "                    n += 1\n",
    "                    self.samples.append({\n",
    "                        'path': os.path.join(label_dir, video_file),\n",
    "                        'label': self.label_map[label]\n",
    "                    })\n",
    "            print(f\"Loaded {n} samples for label {label}\")\n",
    "\n",
    "    def get_label_map(self):\n",
    "        return self.label_map\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        video = cv2.VideoCapture(sample['path'])\n",
    "        \n",
    "        # MHI 시퀀스 생성\n",
    "        mhi_sequence = []\n",
    "        prev_img = None\n",
    "        frame_count = 0\n",
    "        \n",
    "        while frame_count < self.frame_count:\n",
    "            ret, curr_img = video.read()\n",
    "            if not ret:\n",
    "                break\n",
    "                \n",
    "            if prev_img is not None:\n",
    "                mhi = get_mhi(prev_img, curr_img)\n",
    "                mhi_sequence.append(mhi)\n",
    "                \n",
    "            prev_img = curr_img\n",
    "            frame_count += 1\n",
    "            \n",
    "        video.release()\n",
    "        \n",
    "        # numpy array로 변환\n",
    "        mhi_sequence = np.array(mhi_sequence)\n",
    "        mhi_tensor = torch.from_numpy(mhi_sequence).float()\n",
    "        # 채널 차원 추가 (N, H, W) -> (N, 1, H, W)\n",
    "        mhi_tensor = mhi_tensor.unsqueeze(1)\n",
    "        \n",
    "        return mhi_tensor, sample['label'], len(mhi_sequence)\n",
    "    \n",
    "\n",
    "def collate_fn(batch):\n",
    "   # 배치 내의 데이터, 라벨, 길이를 분리\n",
    "   sequences, labels, lengths = zip(*batch)\n",
    "   \n",
    "   # 가장 긴 시퀀스에 맞춰 패딩\n",
    "   padded_sequences = pad_sequence(sequences, batch_first=True)\n",
    "   \n",
    "   # 길이에 따라 정렬 (긴 것부터)\n",
    "   lengths = torch.LongTensor(lengths)\n",
    "   lengths, sort_idx = lengths.sort(descending=True)\n",
    "   padded_sequences = padded_sequences[sort_idx]\n",
    "   labels = torch.LongTensor([labels[i] for i in sort_idx])\n",
    "   \n",
    "   return padded_sequences, labels, lengths\n",
    "\n",
    "\n",
    "def get_dataloader(root_dir, batch_size, frame_count):\n",
    "    dataset = ActionDataset(root_dir, frame_count)\n",
    "    train_dataset, test_dataset = random_split(dataset, [len(dataset) - 100, 100])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "\n",
    "class ConvLSTMCell(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_channels: int,\n",
    "                 hidden_channels: int,\n",
    "                 kernel_size: int,\n",
    "                 input_size: tuple[int, int]):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_channels = input_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.height, self.width = input_size\n",
    "        self.padding = kernel_size // 2\n",
    "\n",
    "        self.conv = nn.Conv2d(\n",
    "           in_channels=input_channels + hidden_channels,\n",
    "           out_channels=4 * hidden_channels,  # i, f, o, g gates\n",
    "           kernel_size=kernel_size,\n",
    "           padding=self.padding\n",
    "        )\n",
    "\n",
    "    def forward(self, x, hidden_state=None):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        if hidden_state is None:\n",
    "            h_state = torch.zeros(batch_size, self.hidden_channels, \n",
    "                                self.height, self.width).to(x.device)\n",
    "            c_state = torch.zeros(batch_size, self.hidden_channels, \n",
    "                                self.height, self.width).to(x.device)\n",
    "        else:\n",
    "            h_state, c_state = hidden_state\n",
    "\n",
    "        combined = torch.cat([x, h_state], dim=1)\n",
    "        gates = self.conv(combined)\n",
    "\n",
    "        # gates를 분리합니다\n",
    "        i_gate, f_gate, o_gate, g_gate = gates.chunk(4, dim=1)\n",
    "\n",
    "        # 활성화 함수 적용\n",
    "        i_gate = torch.sigmoid(i_gate)\n",
    "        f_gate = torch.sigmoid(f_gate)\n",
    "        o_gate = torch.sigmoid(o_gate)\n",
    "        g_gate = torch.tanh(g_gate)\n",
    "\n",
    "        # 새로운 cell state 계산\n",
    "        c_state = f_gate * c_state + i_gate * g_gate\n",
    "        # 새로운 hidden state 계산\n",
    "        h_state = o_gate * torch.tanh(c_state)\n",
    "\n",
    "        return h_state, c_state    \n",
    "\n",
    "\n",
    "class ConvLSTM(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels, kernel_size, input_size, num_layers, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_channels = input_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.num_layers = num_layers\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # 여러 층의 ConvLSTM 셀을 생성\n",
    "        cell_list = []\n",
    "        for i in range(num_layers):\n",
    "           cur_input_channels = input_channels if i == 0 else hidden_channels\n",
    "           cell_list.append(ConvLSTMCell(\n",
    "               input_channels=cur_input_channels,\n",
    "               hidden_channels=hidden_channels,\n",
    "               kernel_size=kernel_size,\n",
    "               input_size=input_size\n",
    "           ))\n",
    "        self.cell_list = nn.ModuleList(cell_list)\n",
    "\n",
    "        # 전역 평균 풀링 추가\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        # 분류기 추가\n",
    "        self.classifier = nn.Linear(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        입력:\n",
    "            x: (batch_size, time_steps, channels, height, width)\n",
    "        출력:\n",
    "            final_output: (batch_size, num_classes)\n",
    "        \"\"\"\n",
    "        time_steps = x.size(1)\n",
    "        \n",
    "        # 각 층의 마지막 상태만 저장\n",
    "        last_states = [None] * self.num_layers\n",
    "        cur_layer_input = x\n",
    "\n",
    "        for layer_idx in range(self.num_layers):\n",
    "            h_state = None\n",
    "            \n",
    "            # 각 타임스텝 처리\n",
    "            for t in range(time_steps):\n",
    "                h_state, c_state = self.cell_list[layer_idx](\n",
    "                    cur_layer_input[:, t, :, :, :],\n",
    "                    last_states[layer_idx]\n",
    "                )\n",
    "                last_states[layer_idx] = (h_state, c_state)\n",
    "            \n",
    "            # 다음 층의 입력 준비\n",
    "            if layer_idx < self.num_layers - 1:\n",
    "                cur_layer_input = h_state.unsqueeze(1).expand(-1, time_steps, -1, -1, -1)\n",
    "        \n",
    "        # 마지막 층의 마지막 hidden state 사용\n",
    "        final_hidden = h_state  # (batch_size, hidden_channels, height, width)\n",
    "        \n",
    "        # 전역 평균 풀링\n",
    "        pooled = self.global_pool(final_hidden)  # (batch_size, hidden_channels, 1, 1)\n",
    "        flattened = pooled.view(pooled.size(0), -1)  # (batch_size, hidden_channels)\n",
    "        \n",
    "        # 분류\n",
    "        output = self.classifier(flattened)  # (batch_size, num_classes)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target, length) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "       \n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f'Training... [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
    "                f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def test(model, test_loader, device, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target, length in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'Test set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{total} ({100. * correct / total:.0f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def main():\n",
    "    # 하이퍼파라미터 설정\n",
    "    input_channels = 1  # MHI는 그레이스케일\n",
    "    hidden_channels = 32\n",
    "    kernel_size = 3\n",
    "    num_layers = 2\n",
    "    num_classes = 6  # 분류할 동작 클래스 수\n",
    "    batch_size = 4\n",
    "    num_epochs = 100\n",
    "    frame_count = 50\n",
    "    learning_rate = 0.001\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # 데이터셋 로드\n",
    "    train_loader, test_loader = get_dataloader(root_dir='dataset', batch_size=batch_size, frame_count=frame_count)\n",
    "    \n",
    "    # 첫 번째 배치로부터 입력 크기 얻기\n",
    "    sample_data, *_ = next(iter(train_loader))\n",
    "    input_size = (sample_data.size(3), sample_data.size(4))\n",
    "\n",
    "    # 모델 초기화\n",
    "    model = ConvLSTM(\n",
    "        input_channels=input_channels,\n",
    "        hidden_channels=hidden_channels,\n",
    "        kernel_size=kernel_size,\n",
    "        input_size=input_size,\n",
    "        num_layers=num_layers,\n",
    "        num_classes=num_classes,\n",
    "    ).to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # 학습 실행\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        print(f\"Epoch {epoch} of {num_epochs}...\")\n",
    "        train(model, train_loader, criterion, optimizer, device)\n",
    "\n",
    "    # 테스트\n",
    "    test(model, test_loader, device, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
